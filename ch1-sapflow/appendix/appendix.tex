\section{Appendix: Markov Chain Monte Carlo}

The MCMC method we adopt computes the likelihood function, assuming that the sap flow measurement errors are normally distributed, and uses the Metropolis-Hastings algorithm to select new members of the chain from a proposal distribution [e.g., \textit{Sivia} 2006]. We used the python PyMC module to execute this analysis [\textit{Patil et al.}, 2010]. The standard deviation of the measurement error for each sensor was determined from the noise floor of the sensor's power spectrum, using Parseval's theorem; the standard deviation for most sensors was 1-3\%, and the largest standard deviation was 8\%.  The Metropolis-Hastings algorithm guarantees convergence of the Markov chains, but convergence is slow when a high rate of rejection ($>>$50\%) of the proposed values occurs, a common circumstance for problems with a large number of parameters.  We investigated marginalization over errors in the environmental variables (temperature, relative humidity, radiation, and soil moisture) adopting a single test sensor for which this problem was computational tractable.  The most likely parameter values for this test sensor were slightly different from those derived assuming the environmental parameters are perfectly known, but the differences were small compared to the differences between sensors and compared to the range of the parameter space.  The 95\% confidence intervals did not widen noticeably in this test, but the slight differences in median values suggest that the 95\% confidence intervals quoted here underestimate the parameter uncertainties by up to a factor of 3.  However, all parameter distribution widths remained a small fraction of the spread in most likely parameters values derived for each species as a whole.  Thus, while the confidence intervals listed in Table A2 should be viewed as lower limits to the true error for a given tree's parameters, we do not expect unaccounted-for uncertainties in environmental variables to significantly impact our species-wide conclusions.

We adopt uniform priors for the proposal distributions of the unknowns, and each chain is initialized with a random value within the prior range.  The adopted priors for the free parameters are given in Table A3, and we imposed them after exploration of the full range of parameters.  Following an initial ``burn in" period, we establish convergence and independence following \textit{Raftery and Lewis} [1995].  Figure A1 shows typical results from this analysis for two example trees.  For both trees, $\frac{g_{\rm c,\,max}}{\alpha}$ and $D_o$ are correlated, consistent with the results of \textit{Oren et al.} [1999]; $R^2$ values for $\frac{g_{\rm c,\,max}}{\alpha}$ -- $D_o$ correlation ranged from 0.92 to 0.99 over all trees.  For most madrone trees, $\beta$ and $\theta_0$ covary in a nonlinear way, as shown in Figure A1 (Tree 16); $\beta$ and $\theta_0$ did not covary in this way for other species.  Other parameters are minimally correlated, and the degree of parameter independence shown in Figure A1 is typical for all sensors.
